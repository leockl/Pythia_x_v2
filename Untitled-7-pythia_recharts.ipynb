{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, session\n",
    "import openai\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from flask_session import Session  # This requires Flask-Session\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['SECRET_KEY'] = 'your_secret_key'  # Needed for session management\n",
    "app.config['SESSION_TYPE'] = 'filesystem'  # Sessions stored on the filesystem\n",
    "Session(app)\n",
    "\n",
    "# Replace with your OpenAI API key\n",
    "openai.api_key = 'your_openai_api_key'\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    'dbname': 'public',\n",
    "    'user': 'postgres',\n",
    "    'password': 'abcdabcd',\n",
    "    'host': '136.144.56.123',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "SCHEMA = '''\n",
    "CREATE TABLE trades (\n",
    "exchange character varying(20),\n",
    "symbol character varying(20),\n",
    "price double precision,\n",
    "size double precision,\n",
    "taker_side character varying(5),\n",
    "trade_id character varying(64),\n",
    "event_timestamp timestamp without time zone,\n",
    "atom_timestamp bigint\n",
    ");\n",
    "\n",
    "CREATE TABLE trades_l3 (\n",
    "    exchange character varying(20),\n",
    "    symbol character varying(20),\n",
    "    price double precision,\n",
    "    size double precision,\n",
    "    taker_side character varying(5),\n",
    "    trade_id character varying(64),\n",
    "    maker_order_id character varying(64),\n",
    "    taker_order_id character varying(64),\n",
    "    event_timestamp timestamp without time zone,\n",
    "    atom_timestamp bigint\n",
    ");\n",
    "\n",
    "CREATE TABLE candle (\n",
    "    exchange character varying(20),\n",
    "    symbol character varying(20),\n",
    "    start timestamp without time zone,\n",
    "    \"end\" timestamp without time zone,\n",
    "    \"interval\" character varying(10),\n",
    "    trades integer,\n",
    "    closed boolean,\n",
    "    o double precision,\n",
    "    h double precision,\n",
    "    l double precision,\n",
    "    c double precision,\n",
    "    v double precision,\n",
    "    event_timestamp timestamp without time zone,\n",
    "    atom_timestamp bigint\n",
    ");\n",
    "\n",
    "CREATE TABLE ethereum_blocks (\n",
    "    blocktimestamp timestamp without time zone,\n",
    "    atomtimestamp bigint,\n",
    "    number integer,\n",
    "    hash character(66) NOT NULL,\n",
    "    parenthash character(66),\n",
    "    nonce character(18),\n",
    "    sha3uncles character(66),\n",
    "    logsbloom character(514),\n",
    "    transactionsroot character(66),\n",
    "    stateroot character(66),\n",
    "    receiptsroot character(66),\n",
    "    miner character(42),\n",
    "    difficulty bigint,\n",
    "    totaldifficulty numeric,\n",
    "    extradata text,\n",
    "    size bigint,\n",
    "    gaslimit numeric,\n",
    "    gasused numeric\n",
    ");\n",
    "\n",
    "CREATE TABLE ethereum_logs (\n",
    "    atomtimestamp bigint,\n",
    "    blocktimestamp timestamp without time zone NOT NULL,\n",
    "    logindex integer NOT NULL,\n",
    "    transactionindex integer,\n",
    "    transactionhash character(66) NOT NULL,\n",
    "    blockhash character(66),\n",
    "    blocknumber bigint,\n",
    "    address character(42),\n",
    "    data text,\n",
    "    topic0 text,\n",
    "    topic1 text,\n",
    "    topic2 text,\n",
    "    topic3 text\n",
    ")\n",
    "\n",
    "CREATE TABLE ethereum_transactions (\n",
    "    blocktimestamp timestamp without time zone NOT NULL,\n",
    "    atomtimestamp bigint,\n",
    "    blocknumber integer,\n",
    "    blockhash character(66),\n",
    "    hash character(66) NOT NULL,\n",
    "    nonce text,\n",
    "    transactionindex integer,\n",
    "    fromaddr character(42),\n",
    "    toaddr character(42),\n",
    "    value numeric,\n",
    "    gas bigint,\n",
    "    gasprice bigint,\n",
    "    input text,\n",
    "    maxfeepergas bigint,\n",
    "    maxpriorityfeepergas bigint,\n",
    "    type text\n",
    ")\n",
    "\n",
    "CREATE TABLE ethereum_token_transfers (\n",
    "    atomtimestamp bigint,\n",
    "    blocktimestamp timestamp without time zone NOT NULL,\n",
    "    tokenaddr character(42),\n",
    "    fromaddr text,\n",
    "    toaddr text,\n",
    "    value numeric,\n",
    "    transactionhash character(66) NOT NULL,\n",
    "    logindex integer NOT NULL,\n",
    "    blocknumber bigint,\n",
    "    blockhash character(66)\n",
    ")\n",
    "'''\n",
    "\n",
    "# Initialize session key for storing conversation\n",
    "SESSION_KEY = 'conversation'\n",
    "\n",
    "def execute_query(query):\n",
    "    \"\"\"Executes a SQL query and returns the results.\"\"\"\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    cursor = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        conn.commit()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "def determine_chart_type(data):\n",
    "    \"\"\"Determines the most appropriate chart type based on data types.\"\"\"\n",
    "    if any('timestamp' in column for column in data[0].keys()):\n",
    "        return ['line']\n",
    "    elif len(data[0]) == 2:\n",
    "        return ['scatter']\n",
    "    else:\n",
    "        return ['bar', 'pie']  # Include 'pie' for categorical data\n",
    "\n",
    "def generate_charts(data, chart_types):\n",
    "    \"\"\"Prepares data for charts to be rendered by Recharts on the frontend.\"\"\"\n",
    "    charts = {}\n",
    "    for chart_type in chart_types:\n",
    "        chart_data = []\n",
    "        if chart_type in ['line', 'scatter', 'bar']:\n",
    "            for item in data:\n",
    "                entry = {key: value for key, value in item.items()}\n",
    "                chart_data.append(entry)\n",
    "        elif chart_type == 'pie':\n",
    "            labels = [str(item[list(item.keys())[0]]) for item in data]\n",
    "            sizes = [item[list(item.keys())[1]] for item in data]\n",
    "            chart_data = [{\"name\": label, \"value\": size} for label, size in zip(labels, sizes)]\n",
    "\n",
    "        charts[chart_type] = chart_data\n",
    "    \n",
    "    return charts\n",
    "\n",
    "def generate_summary(data):\n",
    "    \"\"\"Generates a summary for given data using OpenAI's API.\"\"\"\n",
    "    prompt = \"Summarize this data in natural language: \" + str(data)\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Adjust according to the latest available model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        summary = response.choices[0].message['content']\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        return \"Error generating summary.\"\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def handle_query():\n",
    "    user_question = request.json.get('question')\n",
    "    conversation_history = session.get(SESSION_KEY, [])\n",
    "    \n",
    "    try:\n",
    "        # Include conversation history in the request to OpenAI\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Adjust according to the latest available model\n",
    "            messages=conversation_history + [\n",
    "                {\"role\": \"system\", \"content\": f\"\"\"You are a program which translates natural language into read-only SQL commands. \\\n",
    "                                               Use the following table schema: {SCHEMA}. You only output SQL queries. Your \\\n",
    "                                               queries are designed to be used as timeseries charts from Apache Superset. \\\n",
    "                                               Trading pairs are in the form \"<base>.<quote>\", where <base> and <quote> are \\\n",
    "                                               uppercase. Exchanges \"binance\" and \"coinbase\" use the trades_l3 table for their \\\n",
    "                                               trades, all other exchanges use the trades table. All exchange names are \\\n",
    "                                               lowercase. Input:\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Translate this natural language question to SQL: \\\"{user_question}\\\"\"}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        sql_query = response.choices[0].message['content'].strip()\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": sql_query})\n",
    "        session[SESSION_KEY] = conversation_history  # Update session with the new history\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Error generating SQL query: {e}\"}), 500\n",
    "\n",
    "    # Execute the SQL query\n",
    "    query_result = execute_query(sql_query)\n",
    "    if query_result is None:\n",
    "        return jsonify({\"error\": \"Failed to execute SQL query\"}), 500\n",
    "\n",
    "    # Generate a chart if applicable and requested\n",
    "    charts = {}\n",
    "    summary = \"\"\n",
    "    if 'chart' in user_question.lower():\n",
    "        # Determine the most appropriate chart type based on the query result\n",
    "        chart_types = determine_chart_type(query_result)\n",
    "        charts = generate_charts(query_result, chart_types)\n",
    "        summary = generate_summary(query_result)\n",
    "\n",
    "        # Adjust the response to include both charts if they exist\n",
    "        response_data = {}\n",
    "        for chart_type, chart_base64 in charts.items():\n",
    "            response_data[chart_type + \"_chart\"] = chart_base64\n",
    "        response_data[\"summary\"] = summary\n",
    "        return jsonify(response_data)\n",
    "    else:\n",
    "        # If not generating a chart, return the query result directly\n",
    "        summary = generate_summary(query_result)\n",
    "        return jsonify({\"result\": query_result, \"summary\": summary})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
