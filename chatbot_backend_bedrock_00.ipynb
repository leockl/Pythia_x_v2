{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 import the OS, Bedrock, ConversationChain, ConversationBufferMemory Langchain Modules\n",
    "import os\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "#2a Write a function for invoking model- client connection with Bedrock with profile, model_id & Inference params- model_kwargs\n",
    "def demo_chatbot():\n",
    "    demo_llm = Bedrock(\n",
    "       credentials_profile_name='default',\n",
    "       model_id='meta.llama2-70b-chat-v1',\n",
    "       model_kwargs= {\n",
    "        \"temperature\": 0.9,\n",
    "        \"top_p\": 0.5,\n",
    "        \"max_gen_len\": 512})\n",
    "    return demo_llm\n",
    "    \n",
    "#2b Test out the LLM with Predict method\n",
    "   # return demo_llm.predict(input_text)\n",
    "#response = demo_chatbot('what is the temprature in london like ?')\n",
    "#print(response)\n",
    "\n",
    "#3 Create a Function for ConversationBufferMemory (llm and max token limit)\n",
    "def demo_memory():\n",
    "    llm_data=demo_chatbot()\n",
    "    memory = ConversationBufferMemory(llm=llm_data, max_token_limit= 512)\n",
    "    return memory\n",
    "\n",
    "#4 Create a Function for Conversation Chain - Input text + Memory\n",
    "def demo_conversation(input_text,memory):\n",
    "    llm_chain_data = demo_chatbot()\n",
    "    llm_conversation= ConversationChain(llm=llm_chain_data,memory= memory,verbose=True)\n",
    "\n",
    "#5 Chat response using Predict (Prompt template)\n",
    "    chat_reply = llm_conversation.predict(input=input_text)\n",
    "    return chat_reply\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_response = demo_conversation(input_text=\"What is the capital of Spain?\", memory=demo_memory())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
