{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, session\n",
    "import openai\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "from flask_session import Session  # This requires Flask-Session\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['SECRET_KEY'] = 'your_secret_key'  # Needed for session management\n",
    "app.config['SESSION_TYPE'] = 'filesystem'  # Sessions stored on the filesystem\n",
    "Session(app)\n",
    "\n",
    "# Replace with your OpenAI API key\n",
    "openai.api_key = 'your_openai_api_key'\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    'dbname': 'postgres',\n",
    "    'user': 'viewer_account',\n",
    "    'password': 'empty',\n",
    "    'host': '136.144.62.142',\n",
    "    'port': '5432'\n",
    "}\n",
    "\n",
    "SCHEMA = '''\n",
    "CREATE TABLE trades (\n",
    "exchange character varying(20),\n",
    "symbol character varying(20),\n",
    "price double precision,\n",
    "size double precision,\n",
    "taker_side character varying(5),\n",
    "trade_id character varying(64),\n",
    "event_timestamp timestamp without time zone,\n",
    "atom_timestamp bigint\n",
    ");\n",
    "\n",
    "CREATE TABLE trades_l3 (\n",
    "    exchange character varying(20),\n",
    "    symbol character varying(20),\n",
    "    price double precision,\n",
    "    size double precision,\n",
    "    taker_side character varying(5),\n",
    "    trade_id character varying(64),\n",
    "    maker_order_id character varying(64),\n",
    "    taker_order_id character varying(64),\n",
    "    event_timestamp timestamp without time zone,\n",
    "    atom_timestamp bigint\n",
    ");\n",
    "\n",
    "CREATE TABLE candle (\n",
    "    exchange character varying(20),\n",
    "    symbol character varying(20),\n",
    "    start timestamp without time zone,\n",
    "    \"end\" timestamp without time zone,\n",
    "    \"interval\" character varying(10),\n",
    "    trades integer,\n",
    "    closed boolean,\n",
    "    o double precision,\n",
    "    h double precision,\n",
    "    l double precision,\n",
    "    c double precision,\n",
    "    v double precision,\n",
    "    event_timestamp timestamp without time zone,\n",
    "    atom_timestamp bigint\n",
    ");\n",
    "\n",
    "CREATE TABLE ethereum_blocks (\n",
    "    blocktimestamp timestamp without time zone,\n",
    "    atomtimestamp bigint,\n",
    "    number integer,\n",
    "    hash character(66) NOT NULL,\n",
    "    parenthash character(66),\n",
    "    nonce character(18),\n",
    "    sha3uncles character(66),\n",
    "    logsbloom character(514),\n",
    "    transactionsroot character(66),\n",
    "    stateroot character(66),\n",
    "    receiptsroot character(66),\n",
    "    miner character(42),\n",
    "    difficulty bigint,\n",
    "    totaldifficulty numeric,\n",
    "    extradata text,\n",
    "    size bigint,\n",
    "    gaslimit numeric,\n",
    "    gasused numeric\n",
    ");\n",
    "\n",
    "CREATE TABLE ethereum_logs (\n",
    "    atomtimestamp bigint,\n",
    "    blocktimestamp timestamp without time zone NOT NULL,\n",
    "    logindex integer NOT NULL,\n",
    "    transactionindex integer,\n",
    "    transactionhash character(66) NOT NULL,\n",
    "    blockhash character(66),\n",
    "    blocknumber bigint,\n",
    "    address character(42),\n",
    "    data text,\n",
    "    topic0 text,\n",
    "    topic1 text,\n",
    "    topic2 text,\n",
    "    topic3 text\n",
    ")\n",
    "\n",
    "CREATE TABLE ethereum_transactions (\n",
    "    blocktimestamp timestamp without time zone NOT NULL,\n",
    "    atomtimestamp bigint,\n",
    "    blocknumber integer,\n",
    "    blockhash character(66),\n",
    "    hash character(66) NOT NULL,\n",
    "    nonce text,\n",
    "    transactionindex integer,\n",
    "    fromaddr character(42),\n",
    "    toaddr character(42),\n",
    "    value numeric,\n",
    "    gas bigint,\n",
    "    gasprice bigint,\n",
    "    input text,\n",
    "    maxfeepergas bigint,\n",
    "    maxpriorityfeepergas bigint,\n",
    "    type text\n",
    ")\n",
    "\n",
    "CREATE TABLE ethereum_token_transfers (\n",
    "    atomtimestamp bigint,\n",
    "    blocktimestamp timestamp without time zone NOT NULL,\n",
    "    tokenaddr character(42),\n",
    "    fromaddr text,\n",
    "    toaddr text,\n",
    "    value numeric,\n",
    "    transactionhash character(66) NOT NULL,\n",
    "    logindex integer NOT NULL,\n",
    "    blocknumber bigint,\n",
    "    blockhash character(66)\n",
    ")\n",
    "'''\n",
    "\n",
    "# Initialize session key for storing conversation\n",
    "SESSION_KEY = 'conversation'\n",
    "\n",
    "def execute_query(query):\n",
    "    \"\"\"Executes a SQL query and returns the results.\"\"\"\n",
    "    conn = psycopg2.connect(**db_params)\n",
    "    cursor = conn.cursor(cursor_factory=RealDictCursor)\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        result = cursor.fetchall()\n",
    "        conn.commit()\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        print(f\"Failed SQL: {query}\")  # Log the failed SQL query for debugging\n",
    "        return None\n",
    "    finally:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "def find_group_column(data):\n",
    "    \"\"\"\n",
    "    Dynamically identifies a potential column for grouping data based on the criterion\n",
    "    of having a moderate number of unique values and being non-numeric, now considering 'time' or 'date' in variable names.\n",
    "    \"\"\"\n",
    "    # Adjust the potential_group_columns list comprehension to exclude numeric columns\n",
    "    potential_group_columns = [col for col in data[0].keys() if not is_numeric(data[0][col]) and not any(substring in col for substring in ['time', 'date'])]\n",
    "    \n",
    "    for col in potential_group_columns:\n",
    "        unique_values = {item[col] for item in data}\n",
    "        if 1 < len(unique_values) <= 10:  # Example threshold, adjust based on your data\n",
    "            return col, True\n",
    "    return None, False\n",
    "\n",
    "def is_numeric(value):\n",
    "    \"\"\"Determines if a value is numeric.\"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def rearrange_columns_for_datetime(data):\n",
    "    \"\"\"\n",
    "    Reorders the columns in each row of the query result, ensuring that date or time related columns are first.\n",
    "    Assumes that 'data' is a list of dictionaries, where each dictionary represents a row.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return data\n",
    "\n",
    "    reordered_data = []\n",
    "    for row in data:\n",
    "        date_time_columns = {key: value for key, value in row.items() if any(substring in key.lower() for substring in ['time', 'date'])}\n",
    "        other_columns = {key: value for key, value in row.items() if key not in date_time_columns}\n",
    "        reordered_row = {**date_time_columns, **other_columns}  # Merge dictionaries, with date/time columns first\n",
    "        reordered_data.append(reordered_row)\n",
    "\n",
    "    return reordered_data\n",
    "\n",
    "def determine_chart_type(data):\n",
    "    \"\"\"\n",
    "    Enhanced to determine the most appropriate chart type based on data types,\n",
    "    including dynamic grouping for multi-line charts. Now more robustly identifies time/date related columns.\n",
    "    Enhancements to ensure date/time columns are prioritized. Data is preprocessed to reorder columns.\n",
    "    \"\"\"\n",
    "    if not data:\n",
    "        return ['text'], None  # New case for empty data\n",
    "    \n",
    "    # Preprocess the data to reorder columns, prioritizing date/time columns\n",
    "    data = rearrange_columns_for_datetime(data)\n",
    "\n",
    "    first_row = data[0]\n",
    "    numeric_columns = [col for col, val in first_row.items() if is_numeric(val)]\n",
    "    # Adjusted to include any column containing 'time' or 'date'\n",
    "    categorical_columns = [col for col in first_row.keys() if col not in numeric_columns and not any(substring in col for substring in ['time', 'date'])]\n",
    "\n",
    "    if any(substring in col for col in first_row for substring in ['time', 'date']):\n",
    "        group_column, is_suitable_for_multi_line = find_group_column(data)\n",
    "        if is_suitable_for_multi_line:\n",
    "            return ['multi-line'], group_column\n",
    "        else:\n",
    "            return ['line'], None\n",
    "    elif len(numeric_columns) > 1:\n",
    "        return ['scatter'], None\n",
    "    elif len(categorical_columns) >= 1 and len(numeric_columns) == 1:\n",
    "        return ['bar', 'pie'], None\n",
    "    else:\n",
    "        return ['text'], None  # Fallback for unexpected data shapes\n",
    "\n",
    "def generate_charts(data, chart_types, group_column=None):\n",
    "    \"\"\"Generates charts from data based on the determined chart types, including multi-line charts with a dynamically determined grouping column.\"\"\"\n",
    "    charts = {}\n",
    "    for chart_type in chart_types:\n",
    "        chart_data = []\n",
    "        if chart_type in ['multi-line', 'line']:\n",
    "            # Ensure time or date columns are used for the x-axis\n",
    "            for item in data:\n",
    "                # Identify time/date columns and numeric columns\n",
    "                time_date_keys = sorted([key for key in item.keys() if any(substring in key.lower() for substring in ['time', 'date'])],\n",
    "                                        key=lambda x: ('time' in x.lower(), 'date' in x.lower()))\n",
    "                numeric_keys = [key for key in item.keys() if is_numeric(item[key]) and key not in time_date_keys]\n",
    "\n",
    "                # Assuming the first time/date column for the x-axis and the first numeric column for the y-axis\n",
    "                if time_date_keys and numeric_keys:\n",
    "                    x_axis_key = time_date_keys[0]\n",
    "                    y_axis_key = numeric_keys[0]  # Use the first available numeric column for the y-axis\n",
    "                    chart_data_entry = {\n",
    "                        'x': item[x_axis_key],\n",
    "                        'y': item[y_axis_key]\n",
    "                    }\n",
    "                    if chart_type == 'multi-line' and group_column:\n",
    "                        # If there's a group_column specified, use it to group data for multi-line charts\n",
    "                        chart_data_entry['group'] = item[group_column]\n",
    "                    chart_data.append(chart_data_entry)\n",
    "                else:\n",
    "                    # If suitable time/date or numeric columns are not found, print a warning\n",
    "                    print(\"Warning: Insufficient data for line/multi-line chart. A time/date and a numeric column are required.\")\n",
    "                    continue  # Skip to the next item\n",
    "\n",
    "            # For multi-line charts, additional logic to handle grouping and plotting multiple lines may be implemented here\n",
    "            # Assume chart_data has been populated as shown in the previous snippet\n",
    "            if chart_type == 'multi-line':\n",
    "                # Group data by the specified group_column for plotting multiple lines\n",
    "                grouped_data = {}\n",
    "                for entry in chart_data:\n",
    "                    group_key = entry['group']  # The group_column value for this entry\n",
    "                    if group_key not in grouped_data:\n",
    "                        grouped_data[group_key] = []\n",
    "                    grouped_data[group_key].append(entry)\n",
    "\n",
    "                # Now, grouped_data contains separate lists of data points for each group\n",
    "                # This data structure is ready for plotting multiple lines within the same chart\n",
    "                # Here, you would iterate over grouped_data and plot each group as a distinct line\n",
    "                # For the purpose of this script, we will simply organize the data for return or further processing\n",
    "                organized_chart_data = []\n",
    "                for group, entries in grouped_data.items():\n",
    "                    # For each group, you could further process or format the entries as needed for your charting tool\n",
    "                    # Here, we append the group data directly, assuming downstream processing will handle the specifics\n",
    "                    organized_chart_data.append({\n",
    "                        'group': group,\n",
    "                        'data': entries  # This contains all the x, y (and potentially other) values for this group\n",
    "                    })\n",
    "\n",
    "                # Replace chart_data with organized_chart_data for multi-line chart preparation\n",
    "                chart_data = organized_chart_data\n",
    "        elif chart_type == 'scatter':\n",
    "            # Prioritize time or date columns for the x-axis if available, otherwise use two numeric columns\n",
    "            for item in data:\n",
    "                # Identify time/date columns and numeric columns\n",
    "                time_date_keys = sorted([key for key in item.keys() if any(substring in key.lower() for substring in ['time', 'date'])],\n",
    "                                        key=lambda x: ('time' in x.lower(), 'date' in x.lower()))\n",
    "                numeric_keys = [key for key in item.keys() if is_numeric(item[key])]\n",
    "\n",
    "                # Decide on the x and y axis keys based on available columns\n",
    "                if time_date_keys:\n",
    "                    x_axis_key = time_date_keys[0]  # Use the first time/date column for the x-axis\n",
    "                    numeric_keys_except_time_date = [key for key in numeric_keys if key not in time_date_keys]\n",
    "                    if numeric_keys_except_time_date:\n",
    "                        y_axis_key = numeric_keys_except_time_date[0]  # Use the first non-time/date numeric column for the y-axis\n",
    "                    else:\n",
    "                        print(\"Warning: No suitable numeric column available for scatter chart y-axis.\")\n",
    "                        continue  # Skip to the next data item\n",
    "                elif len(numeric_keys) >= 2:\n",
    "                    x_axis_key = numeric_keys[0]  # Use the first two numeric columns for the x and y axes\n",
    "                    y_axis_key = numeric_keys[1]\n",
    "                else:\n",
    "                    print(\"Warning: Insufficient data for scatter chart. At least one time/date and one numeric column, or two numeric columns are required.\")\n",
    "                    continue  # Skip to the next data item\n",
    "\n",
    "                # Prepare the chart data entry\n",
    "                chart_data_entry = {\n",
    "                    'x': item[x_axis_key],\n",
    "                    'y': item[y_axis_key],\n",
    "                    'label': item.get(group_column) if group_column else None  # Include group label if applicable\n",
    "                }\n",
    "                chart_data.append(chart_data_entry)\n",
    "        elif chart_type == 'bar':\n",
    "            # Identify the first categorical column as the x-axis and the first numeric column as the y-axis\n",
    "            for item in data:\n",
    "                categorical_keys = [key for key in item.keys() if not is_numeric(item[key]) and not any(substring in key.lower() for substring in ['time', 'date'])]\n",
    "                numeric_keys = [key for key in item.keys() if is_numeric(item[key])]\n",
    "\n",
    "                if categorical_keys and numeric_keys:\n",
    "                    x_axis_key = categorical_keys[0]  # Use the first categorical column for the x-axis\n",
    "                    y_axis_key = numeric_keys[0]  # Use the first numeric column for the y-axis\n",
    "                    chart_data_entry = {\n",
    "                        'category': item[x_axis_key],\n",
    "                        'value': item[y_axis_key]\n",
    "                    }\n",
    "                    chart_data.append(chart_data_entry)\n",
    "                else:\n",
    "                    print(\"Warning: Insufficient data for bar chart. At least one categorical and one numeric column are required.\")\n",
    "        elif chart_type == 'pie':\n",
    "            # Assuming there's a clear distinction between categorical (for labels) and numeric columns (for values)\n",
    "            categorical_keys = [key for key in data[0].keys() if not is_numeric(data[0][key]) and not any(substring in key.lower() for substring in ['time', 'date'])]\n",
    "            numeric_keys = [key for key in data[0].keys() if is_numeric(data[0][key])]\n",
    "\n",
    "            if not categorical_keys or not numeric_keys:\n",
    "                print(\"Warning: Insufficient data for pie chart. A categorical and a numeric column are required.\")\n",
    "                # Handling or notification for insufficient data\n",
    "            else:\n",
    "                x_axis_key = categorical_keys[0]  # The label\n",
    "                y_axis_key = numeric_keys[0]  # The value\n",
    "\n",
    "                chart_data = [{'label': item[x_axis_key], 'value': item[y_axis_key]} for item in data]\n",
    "\n",
    "        charts[chart_type] = chart_data\n",
    "\n",
    "    return charts\n",
    "\n",
    "def generate_summary(data):\n",
    "    \"\"\"Generates a summary for given data using OpenAI's API.\"\"\"\n",
    "    prompt = \"Summarize this data in natural language: \" + str(data)\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Adjust according to the latest available model\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.7\n",
    "        )\n",
    "        summary = response.choices[0].message['content']\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating summary: {e}\")\n",
    "        return \"Error generating summary.\"\n",
    "\n",
    "@app.route('/query', methods=['POST'])\n",
    "def handle_query():\n",
    "    user_question = request.json.get('question')\n",
    "    conversation_history = session.get(SESSION_KEY, [])\n",
    "    \n",
    "    try:\n",
    "        # Include conversation history in the request to OpenAI\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",  # Adjust according to the latest available model\n",
    "            messages=conversation_history + [\n",
    "                {\"role\": \"system\", \"content\": f\"\"\"You are a program which translates natural language into read-only SQL commands. \\\n",
    "                                               Use the following table schema: {SCHEMA}. You only output SQL queries. Your \\\n",
    "                                               queries are designed to be used as timeseries charts from Apache Superset. \\\n",
    "                                               Trading pairs are in the form \"<base>.<quote>\", where <base> and <quote> are \\\n",
    "                                               uppercase. Exchanges \"binance\" and \"coinbase\" use the trades_l3 table for their \\\n",
    "                                               trades, all other exchanges use the trades table. All exchange names are \\\n",
    "                                               lowercase. Input:\"\"\"},\n",
    "                {\"role\": \"user\", \"content\": f\"Translate this natural language question to SQL: \\\"{user_question}\\\"\"}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        sql_query = response.choices[0].message['content'].strip()\n",
    "\n",
    "        # Trim Markdown code block syntax accurately and ensure \"sql\" prefix is properly removed\n",
    "        if sql_query.startswith(\"```sql\"):\n",
    "            sql_query = sql_query[6:]  # Remove starting \"```sql\"\n",
    "        elif sql_query.startswith(\"sql\"):\n",
    "            sql_query = sql_query[3:]  # Remove starting \"sql\" if it's directly at the beginning\n",
    "        \n",
    "        sql_query = sql_query.strip(\" `\\n\")  # Trim spaces, backticks, and newlines from both ends\n",
    "\n",
    "        conversation_history.append({\"role\": \"assistant\", \"content\": sql_query})\n",
    "        session[SESSION_KEY] = conversation_history  # Update session with the new history\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": f\"Error generating SQL query: {e}\"}), 500\n",
    "\n",
    "    # Execute the SQL query\n",
    "    query_result = execute_query(sql_query)\n",
    "    if query_result is None:\n",
    "        return jsonify({\"error\": \"Failed to execute SQL query\"}), 500\n",
    "\n",
    "    # Generate a chart if applicable and requested\n",
    "    charts = {}\n",
    "    summary = \"\"\n",
    "    if 'chart' in user_question.lower():\n",
    "        # Determine the most appropriate chart type based on the query result\n",
    "        chart_types = determine_chart_type(query_result)\n",
    "        charts = generate_charts(query_result, chart_types)\n",
    "        summary = generate_summary(query_result)\n",
    "\n",
    "        # Adjust the response to include both charts if they exist\n",
    "        response_data = {}\n",
    "        for chart_type, chart_base64 in charts.items():\n",
    "            response_data[chart_type + \"_chart\"] = chart_base64\n",
    "        response_data[\"summary\"] = summary\n",
    "        return jsonify(response_data)\n",
    "    else:\n",
    "        # If not generating a chart, return the query result directly\n",
    "        summary = generate_summary(query_result)\n",
    "        return jsonify({\"result\": query_result, \"summary\": summary})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
